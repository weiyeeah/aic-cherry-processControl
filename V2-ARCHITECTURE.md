# 语音后端服务 V2 架构说明

## 🎯 核心设计思路

V2版本采用**进程隔离**的架构，彻底解决了语音识别线程问题导致主服务退出的问题。

## 📊 架构对比

### 原版本问题
```
HTTP服务 (主线程)
├── 语音识别线程
│   ├── WebSocket连接
│   ├── 音频处理
│   └── 异常 → 影响主服务
└── ❌ 线程异常导致整个服务退出
```

### V2版本解决方案
```
HTTP服务 (主进程)           语音识别 (子进程)
├── 接收控制命令              ├── WebSocket连接
├── 管理子进程状态            ├── 音频处理  
├── 进程启动/停止            ├── 文字发送
└── ✅ 子进程崩溃不影响        └── ✅ 独立运行
```

## 🔧 关键文件

### 1. voice-backend-service-v2.py (主服务)
- HTTP服务器，端口8766
- 接收 `/voice/control` 控制命令
- 使用 `subprocess.Popen` 管理子进程
- 子进程异常不影响主服务运行

### 2. voice_worker.py (子进程)
- 独立的语音识别进程
- 调用 `ai_hear_module` 进行语音转录
- 直接发送结果到Cherry Studio
- 进程崩溃可重新启动

## 🚀 工作流程

### 启动语音识别
```
前端点击语音按钮 
→ POST /voice/control {"action": "start"}
→ 主服务启动子进程
→ 子进程开始语音识别
→ 转录结果发送到Cherry Studio
```

### 停止语音识别
```
前端再次点击语音按钮
→ POST /voice/control {"action": "stop"}  
→ 主服务终止子进程
→ 主服务继续运行
```

## ✅ 关键优势

1. **稳定性**: 子进程崩溃不影响主服务
2. **隔离性**: 语音识别问题完全隔离
3. **可控性**: 精确控制子进程生命周期
4. **监控性**: 实时监控子进程状态
5. **简单性**: 主服务逻辑简单清晰

## 🔧 使用方法

```bash
# 启动V2主服务
python backend-voice/voice-backend-service-v2.py

# 测试服务
python test-voice-v2.py
```

## 🛠️ 故障排除

如果子进程无法启动：
1. 检查 `voice_worker.py` 文件存在
2. 检查 `utils/ai_hear_module.py` 可导入
3. 检查WebSocket连接配置

如果转录不工作：
1. 检查子进程日志输出
2. 验证Cherry Studio接收端点
3. 测试WebSocket连接状态

## 📈 性能特点

- 主服务资源占用极低
- 子进程独立管理音频资源
- 进程间通信开销最小
- 支持快速重启恢复